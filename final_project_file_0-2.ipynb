{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e7a32f-65ec-486d-8a94-58fda5457ef6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Heart Disease Detection Model Proposal\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "Heart disease is the second leading cause of death in Canada affecting over 1.2 million citizens (Canada 2022). Since heart disease affects more than 12% of the population and its obvious health consequences, a lot of research has been directed in the treatment and prevention of heart disease (Canada 2022). Although this has had great effects in decreasing the overall prevalence of heart disease in Canada since the early 2000s, there is still a major need to accurately detect the presence of heart disease in the population. What observable cues can be used as predictors for the detection of heart disease? And how can they be used to accurately detect the presence of heart disease. \n",
    "\n",
    "The purpose of this project is to explore how a patient's levels of different measured attributes can predict the presence of heart disease. In addition, we want to build a highly accurate heart disease classification model from these attributes. Since this is a diagnosis classifier, one of our main objectives is to minimize the amount of false negative diagnoses the classifier would predict. This means that when our classifier says that the patient doesn’t have any heart disease, it is very accurate. This is important because the risks associated with having heart disease are very high, and therefore we don’t want our classifier to tell patients they don’t have heart disease when they actually do. \n",
    "\n",
    "In order to build this classifier, we will be using data from the heart disease dataset on UC Irvine’s Machine learning repository called `cleveland.processed.data`. This dataset consists of 14 features from an original set of 76 attributes from 303 consecutive patients referred for coronary angiography at the Cleveland Clinic between May 1981 and September 1984 (Detrano et al., 1989). For this type of analysis, we will be building a classification model using the k-nearest neighbors classifier, which has been commonly used in the medical field as a simple but accurate classifier (Tayeb et al., 2017; Parry et al., 2010) . In this approach, our new data point (patient) will be compared to all other data points we have in our dataset and to find the closest data points to our new one. The classification is determined by the average classification of the closest neighbors. As such, our analysis process will start by determining which attributes to use, then building the classification model using our training data and test it on the remaining data. We will also use the training data to adjust our model and determine the K with the highest accuracy. \n",
    "\n",
    "\n",
    "## Method: \n",
    "Initially, according to our proposal, we built two different models, the first without having balanced data and the next having balanced data, based on 4 quantitative variables selected from the original 14 columns of our dataset. These 4 were chosen because of their quantitative nature and scientific collecting methods. The four predictor variables chosen were: \n",
    "1. `trestbps`: resting blood pressure (unit: mm Hg)\n",
    "2. `chol`: serum cholesterol (unit: Milligrams per deciliter(mg/dl))\n",
    "3. `thalach`: maximum heart rate achieved \n",
    "4. `oldpeak`: ST depression induced by exercise relative to rest (usually mm, measured on electrocardiogram (ECG or EKG)).\n",
    "\n",
    "As for our response variable, we used the presence of heart disease(num). It takes 5 levels based on angiographic disease status where level 0 describes healthy patients and levels 1-4 describes patients diagnosed with increasing stages of heart disease.\n",
    "However, these models are not suitable for clinical use as the recalls were too low, with 50.0% for the unbalanced model and 55.6% for the balanced model. The following method section will be based on the best model we trained with 13 predictor variables that were chosen by the original study among 76 collected variables. These included the following variables:\n",
    "1. `age`: Age of the patient (years)\n",
    "1. `sex`: Sex of the patient (Categorical with 2 levels- Male, Female)\n",
    "1. `cp`: Chest pain type (Categorical with 4 levels-Type 1, Type 2, Type 3 and Type 4) Type 1: typical angina, Type 2: atypical angina, Type 3: non-anginal pain, Type 4: asymptomatic\n",
    "1. `trestbps`: resting blood pressure (unit: mm Hg)\n",
    "1. `chol`: serum cholesterol (unit: Milligrams per deciliter(mg/dl))\n",
    "1. `fbs`: Fasting blood sugar > 120 mg/dl (Categorical with 2 levels-True,False)\n",
    "1. `restecg`: Resting electrocardiographic results (Categorical with 3 levels-N(Normal), L1(Level 1), L2(Level 2))\n",
    "1. `thalach`: Maximum heart rate achieved \n",
    "1. `exang`: Exercise induced angina (Categorical with 2 levels-Yes, No)\n",
    "1. `oldpeak`: ST depression induced by exercise relative to rest (usually mm, measured on electrocardiogram (ECG or EKG)).\n",
    "1. `slope`: The slope of the peak exercise ST segment (categorical with 3 levels-Up, Flat, Down)\n",
    "1. `ca`: Number of major vessels (0-3) colored by flourosopy (Categorical with 4 levels-0, 1, 2, 3)\n",
    "1. `thal`: The heart status as retrieved from Thallium test (Categorical with 3 levels-N(normal),FD(fixed defect), RD(reversible defect)\n",
    "\n",
    "For our model training, we will use 75% of the entire dataset as a training set to train our classifier. We will ensure that our predictors are standardized, and the diagnosis presence (0-4) is balanced. Using a parameter grid with a range of k neighbor values, we will tune our model with $k$-fold cross validation. After fitting our predictors and target columns we will plot the $k$ value (x-axis) against the mean validation score (y-axis) to determine the $k$-value that gives us the highest accuracy. Finally, we will evaluate our model on the test set, by comparing the true diagnosis on the test set with our predictions to calculate accuracy. \n",
    "\n",
    "As a part of tuning the classifier and to visualize the result of whether or not our model has good accuracy, we will use a line plot to show the relationship between a range of K neighbours and accuracy estimates from the test datasets. \n",
    "\n",
    "### Expected Results:\n",
    "We anticipate finding a relationship between our 4 predictor variables and the presence or absence of heart disease. This classifier could have major impacts on the early detection of heart disease, allowing for earlier treatment and better prevention, potentially saving lives. In addition, this project could provide a basis for further research in the development of more accurate classifying models of heart disease, e.g. by further investigation into relevant predictor variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cad2b1-f1d8-4bb4-8b35-2cdbf8c2a9ab",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "We first start off by loading dependencies below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "176ffc51-c055-4b8c-bd96-96d9806c90c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.3 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from pandas==1.5.3) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from pandas==1.5.3) (1.26.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn==1.2.0 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from scikit-learn==1.2.0) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from scikit-learn==1.2.0) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from scikit-learn==1.2.0) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from scikit-learn==1.2.0) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: altair==4.2.2 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (4.2.2)\n",
      "Requirement already satisfied: entrypoints in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from altair==4.2.2) (0.4)\n",
      "Requirement already satisfied: jinja2 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from altair==4.2.2) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from altair==4.2.2) (4.20.0)\n",
      "Requirement already satisfied: numpy in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from altair==4.2.2) (1.26.2)\n",
      "Requirement already satisfied: pandas>=0.18 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from altair==4.2.2) (1.5.3)\n",
      "Requirement already satisfied: toolz in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from altair==4.2.2) (0.12.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair==4.2.2) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair==4.2.2) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair==4.2.2) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair==4.2.2) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from pandas>=0.18->altair==4.2.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from pandas>=0.18->altair==4.2.2) (2023.3.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from jinja2->altair==4.2.2) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas>=0.18->altair==4.2.2) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/92/1a/cd3e0c90d1a763ad90073e13b189b4702f11becf4e71dbbad70a7a149811/matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/e2/83/29a63bbc72839cc6b24b5a0e3d004d4ed4e8439f26460ad9a34e39251904/contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/46/01/4d8c7ac72133a679ec6cedc9cef97d47d02411b431ba6ef014e563f7989c/fonttools-4.46.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading fonttools-4.46.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (156 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.2/156.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/17/ba/17a706b232308e65f57deeccae503c268292e6a091313f6ce833a23093ea/kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Obtaining dependency information for pillow>=8 from https://files.pythonhosted.org/packages/6f/d8/f31dd84b4363b5f24c71b25a13ec3855f5ff233e07e1c3f1f8e979e12be2/Pillow-10.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading Pillow-10.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/a/UBC/dsci100/venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.46.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/6f/d8/f31dd84b4363b5f24c71b25a13ec3855f5ff233e07e1c3f1f8e979e12be2/Pillow-10.1.0-cp311-cp311-manylinux_2_28_x86_64.whl\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading Pillow-10.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.46.0 kiwisolver-1.4.5 matplotlib-3.8.2 pillow-10.1.0 pyparsing-3.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.5.3\n",
    "!pip install scikit-learn==1.2.0\n",
    "!pip install altair==4.2.2\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bf1e42a-633c-4fec-b0c7-81d526b6e15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import set_config\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Simplify working with large datasets in Altair\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Output dataframes instead of arrays\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e51c6e-5f2d-44d9-b8ac-ca8eec70bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=330)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec7f1b-904a-4cfb-9878-466fc80f3f60",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "\n",
    "Utilizing `pd.read_csv()` we can read in the dataset from  as detailed below. We will also isolate our predictors and target. We can also split it into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de0b729-2cba-4811-a0fb-40a63c6e74dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  heart_disease_presence  \n",
       "0      3.0  0.0  6.0                       0  \n",
       "1      2.0  3.0  3.0                       2  \n",
       "2      2.0  2.0  7.0                       1  \n",
       "3      3.0  0.0  3.0                       0  \n",
       "4      1.0  0.0  3.0                       0  \n",
       "..     ...  ...  ...                     ...  \n",
       "298    2.0  0.0  7.0                       1  \n",
       "299    2.0  2.0  7.0                       2  \n",
       "300    2.0  1.0  7.0                       3  \n",
       "301    2.0  1.0  3.0                       1  \n",
       "302    1.0    ?  3.0                       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'heart_disease_presence']\n",
    "url = 'https://github.com/CCWebb14/DSCI100_Group_Project/blob/main/data/processed.cleveland.data?raw=true'\n",
    "\n",
    "cleveland = pd.read_csv(url, names=col_names)\n",
    "\n",
    "cleveland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f6208-a92b-46fe-8d21-1a529e4572a1",
   "metadata": {},
   "source": [
    "###  Dataset preprocessing\n",
    "\n",
    "The data was already processed into 14 columns in total with 13 selected variables used for establishing a probability model in Detrano et al.’s study (1984). During the preprocessing of the dataset, rows with empty values were dropped, and levels of 1 to 4 indicated positive heart disease in the column heart_disease_presence were converted to 1 and the absence of heart disease remained as 0. The preprocessed dataset consisted of 297 observations with 14 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ca2974-24d1-4d73-956c-9c5ba998f61b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  heart_disease_presence  \n",
       "0      3.0  0.0  6.0                       0  \n",
       "1      2.0  3.0  3.0                       1  \n",
       "2      2.0  2.0  7.0                       1  \n",
       "3      3.0  0.0  3.0                       0  \n",
       "4      1.0  0.0  3.0                       0  \n",
       "..     ...  ...  ...                     ...  \n",
       "298    2.0  0.0  7.0                       1  \n",
       "299    2.0  2.0  7.0                       1  \n",
       "300    2.0  1.0  7.0                       1  \n",
       "301    2.0  1.0  3.0                       1  \n",
       "302    1.0    ?  3.0                       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_values_greater_than_1(value):\n",
    "    if value > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "cleveland['heart_disease_presence'] = cleveland['heart_disease_presence'].apply(replace_values_greater_than_1)\n",
    "cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d70251bf-400d-4a9c-b870-5f5c819e13a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleveland = cleveland[~cleveland.isin(['?']).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf3c92-b49d-4c99-bc13-cfb70aab2a7f",
   "metadata": {},
   "source": [
    "Then, we randomly split the dataset into a 75% training set (222 observations) and a 25% testing set (75 observations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5bdfd6-35f6-4e76-85df-cb84a47a794a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "10   57.0  1.0  4.0     140.0  192.0  0.0      0.0    148.0    0.0      0.4   \n",
       "215  56.0  1.0  1.0     120.0  193.0  0.0      2.0    162.0    0.0      1.9   \n",
       "117  35.0  0.0  4.0     138.0  183.0  0.0      0.0    182.0    0.0      1.4   \n",
       "280  57.0  1.0  4.0     110.0  335.0  0.0      0.0    143.0    1.0      3.0   \n",
       "20   64.0  1.0  1.0     110.0  211.0  0.0      2.0    144.0    1.0      1.8   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "11   56.0  0.0  2.0     140.0  294.0  0.0      2.0    153.0    0.0      1.3   \n",
       "229  66.0  1.0  4.0     112.0  212.0  0.0      2.0    132.0    1.0      0.1   \n",
       "207  50.0  1.0  4.0     144.0  200.0  0.0      2.0    126.0    1.0      0.9   \n",
       "259  57.0  1.0  2.0     124.0  261.0  0.0      0.0    141.0    0.0      0.3   \n",
       "224  63.0  0.0  4.0     108.0  269.0  0.0      0.0    169.0    1.0      1.8   \n",
       "\n",
       "     slope   ca thal  heart_disease_presence  \n",
       "10     2.0  0.0  6.0                       0  \n",
       "215    2.0  0.0  7.0                       0  \n",
       "117    1.0  0.0  3.0                       0  \n",
       "280    2.0  1.0  7.0                       1  \n",
       "20     2.0  0.0  3.0                       0  \n",
       "..     ...  ...  ...                     ...  \n",
       "11     2.0  0.0  3.0                       0  \n",
       "229    1.0  1.0  3.0                       1  \n",
       "207    2.0  0.0  7.0                       1  \n",
       "259    1.0  0.0  7.0                       1  \n",
       "224    2.0  2.0  3.0                       1  \n",
       "\n",
       "[222 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleveland_train, cleveland_test = train_test_split(cleveland, test_size=0.25)\n",
    "cleveland_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098f61a-15c2-4803-9c97-2c8ac1b19b54",
   "metadata": {},
   "source": [
    "To build a classifier using K-nearest neighbours, it was essential to scale all the predictors, so standardizing the predictors is performed through preprocessing using the `StandardScaler()` function in the `scikit-learn` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38cea1e8-2b68-4d1e-8314-bd6f01ad38c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleveland_preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']),\n",
    "    remainder = 'passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "cleveland_train_scaled = cleveland_preprocessor.fit_transform(cleveland_train)\n",
    "cleveland_test_scaled = cleveland_preprocessor.fit_transform(cleveland_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25177563-0d22-4220-8484-95781a67bfd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Disease Presence Counts\n",
    "\n",
    "The training set and testing set were transformed separately to prevent data leakage. The training set consisted of 119 observations of no presence of heart disease and 103 observations of positive presence of heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdfad28b-b561-4afa-9f48-34286d1738ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_disease_presence</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   heart_disease_presence  count\n",
       "0                       0    119\n",
       "1                       1    103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_presence_counts = pd.DataFrame(cleveland_train_scaled['heart_disease_presence'].value_counts()).reset_index().rename(\n",
    "    columns={'index': 'heart_disease_presence', 'heart_disease_presence':'count'})\n",
    "\n",
    "disease_presence_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21fe84-8625-4330-a45e-b4aa1ca66514",
   "metadata": {},
   "source": [
    "This training dataset was balanced using the `resample()` method, so both the negative and positive presence of heart diseases have 119 observations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa535d6-ea49-4dea-afef-9de3753d3587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    119\n",
       "0    119\n",
       "Name: heart_disease_presence, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_heart_disease = cleveland_train_scaled[cleveland_train_scaled['heart_disease_presence'] == 1]\n",
    "negative_heart_disease = cleveland_train_scaled[cleveland_train_scaled['heart_disease_presence'] == 0]\n",
    "\n",
    "positive_heart_disease_upsample = resample(\n",
    "    positive_heart_disease, n_samples=negative_heart_disease.shape[0]\n",
    ")\n",
    "upsampled_positive_heart_disease = pd.concat((positive_heart_disease_upsample, negative_heart_disease))\n",
    "upsampled_positive_heart_disease['heart_disease_presence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf18ad2c-b327-4739-b828-306a7a9baa5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = upsampled_positive_heart_disease.drop(columns = {'heart_disease_presence'})\n",
    "y_train = upsampled_positive_heart_disease['heart_disease_presence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006eb2a4-e00d-4651-a922-26f5e30b10c2",
   "metadata": {},
   "source": [
    "Using a parameter grid with a range of 0 to 30 (exclusive) K-neighbours, we tuned our model with 10-fold cross-validation. `GridSearchCV()` method was used for tuning and scoring and was based on recall for clinical reasons to place focus on low false negatives. Then, a line graph (Figure 1) was generated after fitting the tuned grid, to show the accuracies across all numbers of neighbours in the range of 0 to 30. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60df4246-439d-43f4-ad24-6e4b79de1768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"kneighborsclassifier__n_neighbors\": range(1, 40, 1),\n",
    "}\n",
    "cleveland_tune_pipe = make_pipeline(cleveland_preprocessor, KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a171926-2e22-4e0b-9816-a7242067e0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_tune_grid = GridSearchCV(\n",
    "    cleveland_tune_pipe, param_grid, cv=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73f6667a-7506-4142-8635-b7b16521406f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsclassifier__n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019439</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.019239</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>1</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 1}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.874094</td>\n",
       "      <td>0.045350</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017315</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.017689</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>2</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 2}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.861594</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018192</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.017735</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>3</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 3}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.852899</td>\n",
       "      <td>0.042861</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.017517</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>4</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 4}</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.870109</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016983</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.017247</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>5</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.861775</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017995</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>6</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 6}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.844928</td>\n",
       "      <td>0.069274</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.018292</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>7</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 7}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.832609</td>\n",
       "      <td>0.094551</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.017302</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>8</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 8}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.845290</td>\n",
       "      <td>0.088954</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.017651</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.017746</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>9</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 9}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.841123</td>\n",
       "      <td>0.090380</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.018070</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.018345</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>10</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.849275</td>\n",
       "      <td>0.081069</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.023815</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.021795</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>11</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 11}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.874457</td>\n",
       "      <td>0.078683</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>12</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 12}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.849457</td>\n",
       "      <td>0.078951</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.017606</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>13</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 13}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.845290</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.018002</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>14</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 14}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.844928</td>\n",
       "      <td>0.064066</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.017604</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.017727</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>15</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 15}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.857428</td>\n",
       "      <td>0.067278</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.017261</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.018237</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>16</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 16}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.861775</td>\n",
       "      <td>0.061573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016734</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>17</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 17}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.874457</td>\n",
       "      <td>0.064091</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.016772</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>18</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 18}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.870290</td>\n",
       "      <td>0.070383</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.018070</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>19</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 19}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.878623</td>\n",
       "      <td>0.070447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.024662</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>0.024586</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>20</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.857246</td>\n",
       "      <td>0.065080</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.025931</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.022223</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>21</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 21}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.853080</td>\n",
       "      <td>0.065144</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.011221</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>22</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 22}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.011263</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>23</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 23}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.844928</td>\n",
       "      <td>0.066721</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>24</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 24}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.840761</td>\n",
       "      <td>0.066010</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.010477</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.011415</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>25</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 25}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.840761</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>26</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 26}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.836594</td>\n",
       "      <td>0.059446</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>27</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 27}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.836594</td>\n",
       "      <td>0.077229</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.011297</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>28</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 28}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.832246</td>\n",
       "      <td>0.064122</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.011283</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>29</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 29}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.844746</td>\n",
       "      <td>0.064229</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>30</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 30}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.827899</td>\n",
       "      <td>0.056851</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>31</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 31}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.836232</td>\n",
       "      <td>0.062830</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>32</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 32}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.819565</td>\n",
       "      <td>0.069340</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>33</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 33}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.819565</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>34</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 34}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.819565</td>\n",
       "      <td>0.064138</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>35</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 35}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.072089</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.010238</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>36</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 36}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.819565</td>\n",
       "      <td>0.066790</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>37</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 37}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.827899</td>\n",
       "      <td>0.075250</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.010237</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>38</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 38}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.823732</td>\n",
       "      <td>0.073663</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>39</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 39}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.819565</td>\n",
       "      <td>0.078721</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.019439      0.003902         0.019239        0.004747   \n",
       "1        0.017315      0.000872         0.017689        0.001303   \n",
       "2        0.018192      0.001167         0.017735        0.001069   \n",
       "3        0.016889      0.001466         0.017517        0.001227   \n",
       "4        0.016983      0.001473         0.017247        0.001336   \n",
       "5        0.017995      0.000912         0.018120        0.002612   \n",
       "6        0.017273      0.001343         0.018292        0.001135   \n",
       "7        0.017302      0.001123         0.017720        0.000868   \n",
       "8        0.017651      0.000860         0.017746        0.001179   \n",
       "9        0.018070      0.001152         0.018345        0.000952   \n",
       "10       0.023815      0.007246         0.021795        0.012650   \n",
       "11       0.017593      0.001382         0.017621        0.000972   \n",
       "12       0.017606      0.000635         0.017622        0.001093   \n",
       "13       0.017290      0.001099         0.018002        0.001195   \n",
       "14       0.017604      0.001131         0.017727        0.000694   \n",
       "15       0.017261      0.000961         0.018237        0.000732   \n",
       "16       0.016734      0.000677         0.017281        0.000868   \n",
       "17       0.016772      0.001377         0.017497        0.001187   \n",
       "18       0.016689      0.000883         0.018070        0.002313   \n",
       "19       0.024662      0.006771         0.024586        0.010506   \n",
       "20       0.025931      0.007767         0.022223        0.011772   \n",
       "21       0.011221      0.001221         0.012487        0.002744   \n",
       "22       0.010328      0.000140         0.011263        0.000184   \n",
       "23       0.010325      0.000083         0.011304        0.000154   \n",
       "24       0.010477      0.000256         0.011415        0.000286   \n",
       "25       0.010595      0.000529         0.011376        0.000278   \n",
       "26       0.010272      0.000045         0.011255        0.000136   \n",
       "27       0.010288      0.000086         0.011297        0.000174   \n",
       "28       0.010332      0.000107         0.011283        0.000109   \n",
       "29       0.010428      0.000236         0.011575        0.000618   \n",
       "30       0.010327      0.000093         0.011279        0.000142   \n",
       "31       0.010257      0.000019         0.011256        0.000138   \n",
       "32       0.010244      0.000038         0.011286        0.000121   \n",
       "33       0.010263      0.000041         0.011276        0.000071   \n",
       "34       0.010573      0.000621         0.011397        0.000204   \n",
       "35       0.010238      0.000030         0.011269        0.000137   \n",
       "36       0.010307      0.000122         0.011339        0.000222   \n",
       "37       0.010237      0.000038         0.011275        0.000151   \n",
       "38       0.010452      0.000361         0.011552        0.000577   \n",
       "\n",
       "   param_kneighborsclassifier__n_neighbors  \\\n",
       "0                                        1   \n",
       "1                                        2   \n",
       "2                                        3   \n",
       "3                                        4   \n",
       "4                                        5   \n",
       "5                                        6   \n",
       "6                                        7   \n",
       "7                                        8   \n",
       "8                                        9   \n",
       "9                                       10   \n",
       "10                                      11   \n",
       "11                                      12   \n",
       "12                                      13   \n",
       "13                                      14   \n",
       "14                                      15   \n",
       "15                                      16   \n",
       "16                                      17   \n",
       "17                                      18   \n",
       "18                                      19   \n",
       "19                                      20   \n",
       "20                                      21   \n",
       "21                                      22   \n",
       "22                                      23   \n",
       "23                                      24   \n",
       "24                                      25   \n",
       "25                                      26   \n",
       "26                                      27   \n",
       "27                                      28   \n",
       "28                                      29   \n",
       "29                                      30   \n",
       "30                                      31   \n",
       "31                                      32   \n",
       "32                                      33   \n",
       "33                                      34   \n",
       "34                                      35   \n",
       "35                                      36   \n",
       "36                                      37   \n",
       "37                                      38   \n",
       "38                                      39   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "0    {'kneighborsclassifier__n_neighbors': 1}           0.875000   \n",
       "1    {'kneighborsclassifier__n_neighbors': 2}           0.875000   \n",
       "2    {'kneighborsclassifier__n_neighbors': 3}           0.791667   \n",
       "3    {'kneighborsclassifier__n_neighbors': 4}           0.833333   \n",
       "4    {'kneighborsclassifier__n_neighbors': 5}           0.791667   \n",
       "5    {'kneighborsclassifier__n_neighbors': 6}           0.791667   \n",
       "6    {'kneighborsclassifier__n_neighbors': 7}           0.666667   \n",
       "7    {'kneighborsclassifier__n_neighbors': 8}           0.791667   \n",
       "8    {'kneighborsclassifier__n_neighbors': 9}           0.708333   \n",
       "9   {'kneighborsclassifier__n_neighbors': 10}           0.750000   \n",
       "10  {'kneighborsclassifier__n_neighbors': 11}           0.791667   \n",
       "11  {'kneighborsclassifier__n_neighbors': 12}           0.750000   \n",
       "12  {'kneighborsclassifier__n_neighbors': 13}           0.666667   \n",
       "13  {'kneighborsclassifier__n_neighbors': 14}           0.750000   \n",
       "14  {'kneighborsclassifier__n_neighbors': 15}           0.750000   \n",
       "15  {'kneighborsclassifier__n_neighbors': 16}           0.791667   \n",
       "16  {'kneighborsclassifier__n_neighbors': 17}           0.791667   \n",
       "17  {'kneighborsclassifier__n_neighbors': 18}           0.750000   \n",
       "18  {'kneighborsclassifier__n_neighbors': 19}           0.750000   \n",
       "19  {'kneighborsclassifier__n_neighbors': 20}           0.750000   \n",
       "20  {'kneighborsclassifier__n_neighbors': 21}           0.750000   \n",
       "21  {'kneighborsclassifier__n_neighbors': 22}           0.791667   \n",
       "22  {'kneighborsclassifier__n_neighbors': 23}           0.791667   \n",
       "23  {'kneighborsclassifier__n_neighbors': 24}           0.791667   \n",
       "24  {'kneighborsclassifier__n_neighbors': 25}           0.750000   \n",
       "25  {'kneighborsclassifier__n_neighbors': 26}           0.791667   \n",
       "26  {'kneighborsclassifier__n_neighbors': 27}           0.708333   \n",
       "27  {'kneighborsclassifier__n_neighbors': 28}           0.750000   \n",
       "28  {'kneighborsclassifier__n_neighbors': 29}           0.750000   \n",
       "29  {'kneighborsclassifier__n_neighbors': 30}           0.750000   \n",
       "30  {'kneighborsclassifier__n_neighbors': 31}           0.708333   \n",
       "31  {'kneighborsclassifier__n_neighbors': 32}           0.708333   \n",
       "32  {'kneighborsclassifier__n_neighbors': 33}           0.666667   \n",
       "33  {'kneighborsclassifier__n_neighbors': 34}           0.750000   \n",
       "34  {'kneighborsclassifier__n_neighbors': 35}           0.708333   \n",
       "35  {'kneighborsclassifier__n_neighbors': 36}           0.750000   \n",
       "36  {'kneighborsclassifier__n_neighbors': 37}           0.750000   \n",
       "37  {'kneighborsclassifier__n_neighbors': 38}           0.750000   \n",
       "38  {'kneighborsclassifier__n_neighbors': 39}           0.708333   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.833333           0.875000           0.875000   \n",
       "1            0.875000           0.833333           0.833333   \n",
       "2            0.875000           0.833333           0.833333   \n",
       "3            0.875000           0.833333           0.791667   \n",
       "4            0.916667           0.833333           0.791667   \n",
       "5            0.916667           0.750000           0.750000   \n",
       "6            0.916667           0.791667           0.708333   \n",
       "7            0.916667           0.708333           0.708333   \n",
       "8            0.916667           0.708333           0.750000   \n",
       "9            0.916667           0.708333           0.750000   \n",
       "10           0.916667           0.708333           0.833333   \n",
       "11           0.875000           0.708333           0.791667   \n",
       "12           0.875000           0.750000           0.875000   \n",
       "13           0.875000           0.750000           0.833333   \n",
       "14           0.875000           0.750000           0.875000   \n",
       "15           0.875000           0.750000           0.833333   \n",
       "16           0.875000           0.750000           0.833333   \n",
       "17           0.875000           0.750000           0.833333   \n",
       "18           0.875000           0.750000           0.916667   \n",
       "19           0.875000           0.750000           0.916667   \n",
       "20           0.875000           0.750000           0.916667   \n",
       "21           0.875000           0.750000           0.875000   \n",
       "22           0.875000           0.708333           0.875000   \n",
       "23           0.875000           0.708333           0.833333   \n",
       "24           0.875000           0.750000           0.833333   \n",
       "25           0.875000           0.708333           0.833333   \n",
       "26           0.875000           0.708333           0.833333   \n",
       "27           0.875000           0.708333           0.833333   \n",
       "28           0.875000           0.750000           0.833333   \n",
       "29           0.875000           0.750000           0.833333   \n",
       "30           0.916667           0.750000           0.833333   \n",
       "31           0.875000           0.708333           0.833333   \n",
       "32           0.875000           0.750000           0.833333   \n",
       "33           0.875000           0.708333           0.791667   \n",
       "34           0.916667           0.708333           0.791667   \n",
       "35           0.916667           0.708333           0.791667   \n",
       "36           0.916667           0.708333           0.791667   \n",
       "37           0.916667           0.708333           0.791667   \n",
       "38           0.916667           0.708333           0.791667   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.958333           0.791667           0.916667   \n",
       "1            0.875000           0.791667           0.875000   \n",
       "2            0.916667           0.791667           0.916667   \n",
       "3            0.958333           0.833333           0.875000   \n",
       "4            0.916667           0.833333           0.875000   \n",
       "5            0.958333           0.791667           0.833333   \n",
       "6            0.958333           0.791667           0.791667   \n",
       "7            0.958333           0.875000           0.791667   \n",
       "8            0.958333           0.833333           0.833333   \n",
       "9            0.958333           0.875000           0.833333   \n",
       "10           0.958333           0.875000           0.958333   \n",
       "11           0.958333           0.875000           0.833333   \n",
       "12           0.916667           0.791667           0.833333   \n",
       "13           0.958333           0.833333           0.791667   \n",
       "14           0.958333           0.791667           0.916667   \n",
       "15           0.958333           0.875000           0.833333   \n",
       "16           0.958333           0.875000           0.916667   \n",
       "17           0.958333           0.875000           0.916667   \n",
       "18           0.958333           0.875000           0.916667   \n",
       "19           0.958333           0.875000           0.875000   \n",
       "20           0.958333           0.833333           0.875000   \n",
       "21           0.958333           0.833333           0.833333   \n",
       "22           0.958333           0.833333           0.833333   \n",
       "23           0.958333           0.833333           0.833333   \n",
       "24           0.958333           0.833333           0.833333   \n",
       "25           0.916667           0.833333           0.833333   \n",
       "26           0.958333           0.833333           0.875000   \n",
       "27           0.916667           0.833333           0.875000   \n",
       "28           0.958333           0.833333           0.916667   \n",
       "29           0.916667           0.875000           0.833333   \n",
       "30           0.916667           0.875000           0.833333   \n",
       "31           0.916667           0.875000           0.833333   \n",
       "32           0.916667           0.875000           0.833333   \n",
       "33           0.916667           0.875000           0.833333   \n",
       "34           0.916667           0.833333           0.833333   \n",
       "35           0.916667           0.833333           0.833333   \n",
       "36           0.958333           0.833333           0.875000   \n",
       "37           0.958333           0.833333           0.833333   \n",
       "38           0.958333           0.833333           0.833333   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.833333           0.913043           0.869565         0.874094   \n",
       "1            0.875000           0.913043           0.869565         0.861594   \n",
       "2            0.875000           0.826087           0.869565         0.852899   \n",
       "3            0.875000           0.913043           0.913043         0.870109   \n",
       "4            0.833333           0.913043           0.913043         0.861775   \n",
       "5            0.875000           0.869565           0.913043         0.844928   \n",
       "6            0.875000           0.956522           0.869565         0.832609   \n",
       "7            0.833333           0.956522           0.913043         0.845290   \n",
       "8            0.833333           0.956522           0.913043         0.841123   \n",
       "9            0.875000           0.913043           0.913043         0.849275   \n",
       "10           0.833333           0.956522           0.913043         0.874457   \n",
       "11           0.833333           0.956522           0.913043         0.849457   \n",
       "12           0.875000           0.956522           0.913043         0.845290   \n",
       "13           0.875000           0.869565           0.913043         0.844928   \n",
       "14           0.875000           0.869565           0.913043         0.857428   \n",
       "15           0.875000           0.869565           0.956522         0.861775   \n",
       "16           0.875000           0.913043           0.956522         0.874457   \n",
       "17           0.875000           0.913043           0.956522         0.870290   \n",
       "18           0.875000           0.913043           0.956522         0.878623   \n",
       "19           0.833333           0.826087           0.913043         0.857246   \n",
       "20           0.833333           0.826087           0.913043         0.853080   \n",
       "21           0.750000           0.826087           0.913043         0.840580   \n",
       "22           0.791667           0.869565           0.913043         0.844928   \n",
       "23           0.791667           0.869565           0.913043         0.840761   \n",
       "24           0.791667           0.869565           0.913043         0.840761   \n",
       "25           0.791667           0.869565           0.913043         0.836594   \n",
       "26           0.791667           0.869565           0.913043         0.836594   \n",
       "27           0.791667           0.826087           0.913043         0.832246   \n",
       "28           0.791667           0.869565           0.869565         0.844746   \n",
       "29           0.750000           0.826087           0.869565         0.827899   \n",
       "30           0.833333           0.826087           0.869565         0.836232   \n",
       "31           0.750000           0.826087           0.869565         0.819565   \n",
       "32           0.750000           0.826087           0.869565         0.819565   \n",
       "33           0.750000           0.826087           0.869565         0.819565   \n",
       "34           0.750000           0.826087           0.869565         0.815399   \n",
       "35           0.750000           0.826087           0.869565         0.819565   \n",
       "36           0.750000           0.826087           0.869565         0.827899   \n",
       "37           0.750000           0.826087           0.869565         0.823732   \n",
       "38           0.750000           0.826087           0.869565         0.819565   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.045350                4  \n",
       "1         0.031775                9  \n",
       "2         0.042861               13  \n",
       "3         0.046640                6  \n",
       "4         0.048698                8  \n",
       "5         0.069274               19  \n",
       "6         0.094551               29  \n",
       "7         0.088954               16  \n",
       "8         0.090380               22  \n",
       "9         0.081069               15  \n",
       "10        0.078683                2  \n",
       "11        0.078951               14  \n",
       "12        0.082892               16  \n",
       "13        0.064066               19  \n",
       "14        0.067278               10  \n",
       "15        0.061573                7  \n",
       "16        0.064091                2  \n",
       "17        0.070383                5  \n",
       "18        0.070447                1  \n",
       "19        0.065080               11  \n",
       "20        0.065144               12  \n",
       "21        0.063721               25  \n",
       "22        0.066721               18  \n",
       "23        0.066010               23  \n",
       "24        0.063325               23  \n",
       "25        0.059446               26  \n",
       "26        0.077229               26  \n",
       "27        0.064122               30  \n",
       "28        0.064229               21  \n",
       "29        0.056851               31  \n",
       "30        0.062830               28  \n",
       "31        0.069340               34  \n",
       "32        0.071800               34  \n",
       "33        0.064138               34  \n",
       "34        0.072089               39  \n",
       "35        0.066790               34  \n",
       "36        0.075250               31  \n",
       "37        0.073663               33  \n",
       "38        0.078721               34  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model_grid = knn_tune_grid.fit(X_train, y_train)\n",
    "\n",
    "accuracies_grid = pd.DataFrame(knn_model_grid.cv_results_) \n",
    "accuracies_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5843dcd-8af2-4477-b51e-c6b95866e3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-a981cbaafe7746c28e22ec815f7200ac\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a981cbaafe7746c28e22ec815f7200ac\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a981cbaafe7746c28e22ec815f7200ac\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e1fbebc4a8ccf727f33290780387892c\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"x\": {\"field\": \"param_kneighborsclassifier__n_neighbors\", \"scale\": {\"zero\": false}, \"title\": \"Number of Neighbors\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_test_score\", \"scale\": {\"zero\": false}, \"title\": \"Mean Test Score\", \"type\": \"quantitative\"}}, \"title\": \"Figure 1: Mean Test Score against K (Number of Neighbors)\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-e1fbebc4a8ccf727f33290780387892c\": [{\"mean_fit_time\": 0.0194394588470459, \"std_fit_time\": 0.003902142917306261, \"mean_score_time\": 0.019238924980163573, \"std_score_time\": 0.00474677194090135, \"param_kneighborsclassifier__n_neighbors\": 1, \"params\": {\"kneighborsclassifier__n_neighbors\": 1}, \"split0_test_score\": 0.875, \"split1_test_score\": 0.8333333333333334, \"split2_test_score\": 0.875, \"split3_test_score\": 0.875, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.7916666666666666, \"split6_test_score\": 0.9166666666666666, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.9130434782608695, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8740942028985508, \"std_test_score\": 0.045349598276634505, \"rank_test_score\": 4}, {\"mean_fit_time\": 0.017315220832824708, \"std_fit_time\": 0.0008721436356877983, \"mean_score_time\": 0.017689204216003417, \"std_score_time\": 0.001302908338270634, \"param_kneighborsclassifier__n_neighbors\": 2, \"params\": {\"kneighborsclassifier__n_neighbors\": 2}, \"split0_test_score\": 0.875, \"split1_test_score\": 0.875, \"split2_test_score\": 0.8333333333333334, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.875, \"split5_test_score\": 0.7916666666666666, \"split6_test_score\": 0.875, \"split7_test_score\": 0.875, \"split8_test_score\": 0.9130434782608695, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8615942028985508, \"std_test_score\": 0.03177476326836038, \"rank_test_score\": 9}, {\"mean_fit_time\": 0.018192219734191894, \"std_fit_time\": 0.001167468918797607, \"mean_score_time\": 0.01773507595062256, \"std_score_time\": 0.001069293426340388, \"param_kneighborsclassifier__n_neighbors\": 3, \"params\": {\"kneighborsclassifier__n_neighbors\": 3}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.8333333333333334, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.7916666666666666, \"split6_test_score\": 0.9166666666666666, \"split7_test_score\": 0.875, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8528985507246377, \"std_test_score\": 0.04286095591202932, \"rank_test_score\": 13}, {\"mean_fit_time\": 0.01688854694366455, \"std_fit_time\": 0.001466168892377376, \"mean_score_time\": 0.01751716136932373, \"std_score_time\": 0.0012270111311310182, \"param_kneighborsclassifier__n_neighbors\": 4, \"params\": {\"kneighborsclassifier__n_neighbors\": 4}, \"split0_test_score\": 0.8333333333333334, \"split1_test_score\": 0.875, \"split2_test_score\": 0.8333333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.875, \"split7_test_score\": 0.875, \"split8_test_score\": 0.9130434782608695, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8701086956521739, \"std_test_score\": 0.04663966779080025, \"rank_test_score\": 6}, {\"mean_fit_time\": 0.01698319911956787, \"std_fit_time\": 0.0014726263755061968, \"mean_score_time\": 0.017247319221496582, \"std_score_time\": 0.001336349301992208, \"param_kneighborsclassifier__n_neighbors\": 5, \"params\": {\"kneighborsclassifier__n_neighbors\": 5}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.8333333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.875, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.9130434782608695, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8617753623188404, \"std_test_score\": 0.048698199661625606, \"rank_test_score\": 8}, {\"mean_fit_time\": 0.01799466609954834, \"std_fit_time\": 0.0009123342023976902, \"mean_score_time\": 0.01812002658843994, \"std_score_time\": 0.0026119350465090858, \"param_kneighborsclassifier__n_neighbors\": 6, \"params\": {\"kneighborsclassifier__n_neighbors\": 6}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.75, \"split3_test_score\": 0.75, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.7916666666666666, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.875, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.844927536231884, \"std_test_score\": 0.06927399792483334, \"rank_test_score\": 19}, {\"mean_fit_time\": 0.017272639274597167, \"std_fit_time\": 0.0013428849801235389, \"mean_score_time\": 0.018291759490966796, \"std_score_time\": 0.0011349910425669956, \"param_kneighborsclassifier__n_neighbors\": 7, \"params\": {\"kneighborsclassifier__n_neighbors\": 7}, \"split0_test_score\": 0.6666666666666666, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7916666666666666, \"split3_test_score\": 0.7083333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.7916666666666666, \"split6_test_score\": 0.7916666666666666, \"split7_test_score\": 0.875, \"split8_test_score\": 0.9565217391304348, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8326086956521739, \"std_test_score\": 0.09455133442432143, \"rank_test_score\": 29}, {\"mean_fit_time\": 0.017302060127258302, \"std_fit_time\": 0.00112297883400399, \"mean_score_time\": 0.017719531059265138, \"std_score_time\": 0.0008679551695443201, \"param_kneighborsclassifier__n_neighbors\": 8, \"params\": {\"kneighborsclassifier__n_neighbors\": 8}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.7083333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.7916666666666666, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.9565217391304348, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8452898550724639, \"std_test_score\": 0.08895351830253535, \"rank_test_score\": 16}, {\"mean_fit_time\": 0.017650961875915527, \"std_fit_time\": 0.0008596637137416885, \"mean_score_time\": 0.017745780944824218, \"std_score_time\": 0.001179221135323842, \"param_kneighborsclassifier__n_neighbors\": 9, \"params\": {\"kneighborsclassifier__n_neighbors\": 9}, \"split0_test_score\": 0.7083333333333334, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.75, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.9565217391304348, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.841123188405797, \"std_test_score\": 0.0903803966552422, \"rank_test_score\": 22}, {\"mean_fit_time\": 0.01806960105895996, \"std_fit_time\": 0.0011523609823379571, \"mean_score_time\": 0.018344902992248537, \"std_score_time\": 0.0009524693652324708, \"param_kneighborsclassifier__n_neighbors\": 10, \"params\": {\"kneighborsclassifier__n_neighbors\": 10}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.75, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.875, \"split8_test_score\": 0.9130434782608695, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8492753623188406, \"std_test_score\": 0.08106878997650431, \"rank_test_score\": 15}, {\"mean_fit_time\": 0.023815226554870606, \"std_fit_time\": 0.007245722347472496, \"mean_score_time\": 0.021794795989990234, \"std_score_time\": 0.012650495976533905, \"param_kneighborsclassifier__n_neighbors\": 11, \"params\": {\"kneighborsclassifier__n_neighbors\": 11}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.9583333333333334, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.9565217391304348, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8744565217391305, \"std_test_score\": 0.07868264799006194, \"rank_test_score\": 2}, {\"mean_fit_time\": 0.017592740058898926, \"std_fit_time\": 0.001382210618664602, \"mean_score_time\": 0.017620611190795898, \"std_score_time\": 0.000971692981266613, \"param_kneighborsclassifier__n_neighbors\": 12, \"params\": {\"kneighborsclassifier__n_neighbors\": 12}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.9565217391304348, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8494565217391304, \"std_test_score\": 0.07895080510120822, \"rank_test_score\": 14}, {\"mean_fit_time\": 0.017606377601623535, \"std_fit_time\": 0.0006349461724722263, \"mean_score_time\": 0.017621612548828124, \"std_score_time\": 0.0010929645977360812, \"param_kneighborsclassifier__n_neighbors\": 13, \"params\": {\"kneighborsclassifier__n_neighbors\": 13}, \"split0_test_score\": 0.6666666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.875, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.7916666666666666, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.875, \"split8_test_score\": 0.9565217391304348, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8452898550724639, \"std_test_score\": 0.08289186782630026, \"rank_test_score\": 16}, {\"mean_fit_time\": 0.017290306091308594, \"std_fit_time\": 0.001098841247555087, \"mean_score_time\": 0.01800205707550049, \"std_score_time\": 0.0011952086046060333, \"param_kneighborsclassifier__n_neighbors\": 14, \"params\": {\"kneighborsclassifier__n_neighbors\": 14}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.7916666666666666, \"split7_test_score\": 0.875, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.844927536231884, \"std_test_score\": 0.06406592186213642, \"rank_test_score\": 19}, {\"mean_fit_time\": 0.01760427951812744, \"std_fit_time\": 0.001130932547749576, \"mean_score_time\": 0.017727208137512208, \"std_score_time\": 0.000694265822810366, \"param_kneighborsclassifier__n_neighbors\": 15, \"params\": {\"kneighborsclassifier__n_neighbors\": 15}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.875, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.7916666666666666, \"split6_test_score\": 0.9166666666666666, \"split7_test_score\": 0.875, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.857427536231884, \"std_test_score\": 0.06727847224140242, \"rank_test_score\": 10}, {\"mean_fit_time\": 0.01726086139678955, \"std_fit_time\": 0.0009610623294218737, \"mean_score_time\": 0.01823716163635254, \"std_score_time\": 0.0007319778394649296, \"param_kneighborsclassifier__n_neighbors\": 16, \"params\": {\"kneighborsclassifier__n_neighbors\": 16}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.875, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9565217391304348, \"mean_test_score\": 0.8617753623188407, \"std_test_score\": 0.061573152839517774, \"rank_test_score\": 7}, {\"mean_fit_time\": 0.01673431396484375, \"std_fit_time\": 0.0006769197310933918, \"mean_score_time\": 0.01728091239929199, \"std_score_time\": 0.0008684057875143819, \"param_kneighborsclassifier__n_neighbors\": 17, \"params\": {\"kneighborsclassifier__n_neighbors\": 17}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.9166666666666666, \"split7_test_score\": 0.875, \"split8_test_score\": 0.9130434782608695, \"split9_test_score\": 0.9565217391304348, \"mean_test_score\": 0.8744565217391305, \"std_test_score\": 0.06409076190368364, \"rank_test_score\": 2}, {\"mean_fit_time\": 0.01677248477935791, \"std_fit_time\": 0.0013769787642121337, \"mean_score_time\": 0.017496585845947266, \"std_score_time\": 0.0011874932672861216, \"param_kneighborsclassifier__n_neighbors\": 18, \"params\": {\"kneighborsclassifier__n_neighbors\": 18}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.9166666666666666, \"split7_test_score\": 0.875, \"split8_test_score\": 0.9130434782608695, \"split9_test_score\": 0.9565217391304348, \"mean_test_score\": 0.8702898550724638, \"std_test_score\": 0.07038317427007583, \"rank_test_score\": 5}, {\"mean_fit_time\": 0.016689467430114745, \"std_fit_time\": 0.0008828892631454397, \"mean_score_time\": 0.018070340156555176, \"std_score_time\": 0.0023125142028028274, \"param_kneighborsclassifier__n_neighbors\": 19, \"params\": {\"kneighborsclassifier__n_neighbors\": 19}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.9166666666666666, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.9166666666666666, \"split7_test_score\": 0.875, \"split8_test_score\": 0.9130434782608695, \"split9_test_score\": 0.9565217391304348, \"mean_test_score\": 0.8786231884057971, \"std_test_score\": 0.07044749244186307, \"rank_test_score\": 1}, {\"mean_fit_time\": 0.024661684036254884, \"std_fit_time\": 0.00677065929649632, \"mean_score_time\": 0.024585962295532227, \"std_score_time\": 0.010506373006652999, \"param_kneighborsclassifier__n_neighbors\": 20, \"params\": {\"kneighborsclassifier__n_neighbors\": 20}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.9166666666666666, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.875, \"split6_test_score\": 0.875, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8572463768115943, \"std_test_score\": 0.06508037136034117, \"rank_test_score\": 11}, {\"mean_fit_time\": 0.025931191444396973, \"std_fit_time\": 0.00776680279449857, \"mean_score_time\": 0.022222518920898438, \"std_score_time\": 0.011772232931228569, \"param_kneighborsclassifier__n_neighbors\": 21, \"params\": {\"kneighborsclassifier__n_neighbors\": 21}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.9166666666666666, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.875, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8530797101449276, \"std_test_score\": 0.06514413155838777, \"rank_test_score\": 12}, {\"mean_fit_time\": 0.011220836639404297, \"std_fit_time\": 0.001220740192007017, \"mean_score_time\": 0.012487411499023438, \"std_score_time\": 0.002744452589376034, \"param_kneighborsclassifier__n_neighbors\": 22, \"params\": {\"kneighborsclassifier__n_neighbors\": 22}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.875, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8405797101449275, \"std_test_score\": 0.06372074986574669, \"rank_test_score\": 25}, {\"mean_fit_time\": 0.010327529907226563, \"std_fit_time\": 0.0001404493394229126, \"mean_score_time\": 0.011263203620910645, \"std_score_time\": 0.00018405194867606014, \"param_kneighborsclassifier__n_neighbors\": 23, \"params\": {\"kneighborsclassifier__n_neighbors\": 23}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.875, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.7916666666666666, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8449275362318842, \"std_test_score\": 0.0667207956057749, \"rank_test_score\": 18}, {\"mean_fit_time\": 0.010325455665588379, \"std_fit_time\": 8.257839762003871e-05, \"mean_score_time\": 0.011304140090942383, \"std_score_time\": 0.00015427307061003067, \"param_kneighborsclassifier__n_neighbors\": 24, \"params\": {\"kneighborsclassifier__n_neighbors\": 24}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.7916666666666666, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8407608695652173, \"std_test_score\": 0.06600992881024256, \"rank_test_score\": 23}, {\"mean_fit_time\": 0.010477423667907715, \"std_fit_time\": 0.0002555832099959096, \"mean_score_time\": 0.011414718627929688, \"std_score_time\": 0.0002864829312933371, \"param_kneighborsclassifier__n_neighbors\": 25, \"params\": {\"kneighborsclassifier__n_neighbors\": 25}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.7916666666666666, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8407608695652173, \"std_test_score\": 0.06332525940974162, \"rank_test_score\": 23}, {\"mean_fit_time\": 0.010594511032104492, \"std_fit_time\": 0.0005285443743753009, \"mean_score_time\": 0.011376261711120605, \"std_score_time\": 0.00027800745740313645, \"param_kneighborsclassifier__n_neighbors\": 26, \"params\": {\"kneighborsclassifier__n_neighbors\": 26}, \"split0_test_score\": 0.7916666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.7916666666666666, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8365942028985508, \"std_test_score\": 0.059445690929892665, \"rank_test_score\": 26}, {\"mean_fit_time\": 0.010271668434143066, \"std_fit_time\": 4.4751776994424515e-05, \"mean_score_time\": 0.011255192756652831, \"std_score_time\": 0.00013580444697366633, \"param_kneighborsclassifier__n_neighbors\": 27, \"params\": {\"kneighborsclassifier__n_neighbors\": 27}, \"split0_test_score\": 0.7083333333333334, \"split1_test_score\": 0.875, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.875, \"split7_test_score\": 0.7916666666666666, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8365942028985508, \"std_test_score\": 0.07722917664774032, \"rank_test_score\": 26}, {\"mean_fit_time\": 0.010287642478942871, \"std_fit_time\": 8.642272282199833e-05, \"mean_score_time\": 0.011297225952148438, \"std_score_time\": 0.00017378827242443644, \"param_kneighborsclassifier__n_neighbors\": 28, \"params\": {\"kneighborsclassifier__n_neighbors\": 28}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.875, \"split7_test_score\": 0.7916666666666666, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.9130434782608695, \"mean_test_score\": 0.8322463768115943, \"std_test_score\": 0.0641222462634343, \"rank_test_score\": 30}, {\"mean_fit_time\": 0.010331940650939942, \"std_fit_time\": 0.00010717799815323186, \"mean_score_time\": 0.011282515525817872, \"std_score_time\": 0.00010910671107583665, \"param_kneighborsclassifier__n_neighbors\": 29, \"params\": {\"kneighborsclassifier__n_neighbors\": 29}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.9166666666666666, \"split7_test_score\": 0.7916666666666666, \"split8_test_score\": 0.8695652173913043, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8447463768115944, \"std_test_score\": 0.06422887106743302, \"rank_test_score\": 21}, {\"mean_fit_time\": 0.01042778491973877, \"std_fit_time\": 0.00023564086847141784, \"mean_score_time\": 0.011574935913085938, \"std_score_time\": 0.0006176293809428959, \"param_kneighborsclassifier__n_neighbors\": 30, \"params\": {\"kneighborsclassifier__n_neighbors\": 30}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.875, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8278985507246377, \"std_test_score\": 0.05685058555481029, \"rank_test_score\": 31}, {\"mean_fit_time\": 0.010327482223510742, \"std_fit_time\": 9.293060769056567e-05, \"mean_score_time\": 0.011278581619262696, \"std_score_time\": 0.00014172968053985035, \"param_kneighborsclassifier__n_neighbors\": 31, \"params\": {\"kneighborsclassifier__n_neighbors\": 31}, \"split0_test_score\": 0.7083333333333334, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.875, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.8333333333333334, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8362318840579709, \"std_test_score\": 0.06282968078917583, \"rank_test_score\": 28}, {\"mean_fit_time\": 0.010256767272949219, \"std_fit_time\": 1.9356006140513224e-05, \"mean_score_time\": 0.011255908012390136, \"std_score_time\": 0.00013835946168270843, \"param_kneighborsclassifier__n_neighbors\": 32, \"params\": {\"kneighborsclassifier__n_neighbors\": 32}, \"split0_test_score\": 0.7083333333333334, \"split1_test_score\": 0.875, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.875, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8195652173913043, \"std_test_score\": 0.06934029156591817, \"rank_test_score\": 34}, {\"mean_fit_time\": 0.010243988037109375, \"std_fit_time\": 3.8446679558961055e-05, \"mean_score_time\": 0.011286091804504395, \"std_score_time\": 0.00012063881389304528, \"param_kneighborsclassifier__n_neighbors\": 33, \"params\": {\"kneighborsclassifier__n_neighbors\": 33}, \"split0_test_score\": 0.6666666666666666, \"split1_test_score\": 0.875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8333333333333334, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.875, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8195652173913043, \"std_test_score\": 0.0718004056859623, \"rank_test_score\": 34}, {\"mean_fit_time\": 0.010262584686279297, \"std_fit_time\": 4.076695573198924e-05, \"mean_score_time\": 0.011275577545166015, \"std_score_time\": 7.141970110295351e-05, \"param_kneighborsclassifier__n_neighbors\": 34, \"params\": {\"kneighborsclassifier__n_neighbors\": 34}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.875, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.875, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8195652173913043, \"std_test_score\": 0.06413759887930089, \"rank_test_score\": 34}, {\"mean_fit_time\": 0.010572552680969238, \"std_fit_time\": 0.0006206223034932191, \"mean_score_time\": 0.01139676570892334, \"std_score_time\": 0.00020414072747165072, \"param_kneighborsclassifier__n_neighbors\": 35, \"params\": {\"kneighborsclassifier__n_neighbors\": 35}, \"split0_test_score\": 0.7083333333333334, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8153985507246377, \"std_test_score\": 0.07208893089200212, \"rank_test_score\": 39}, {\"mean_fit_time\": 0.010237908363342286, \"std_fit_time\": 2.9531285919685486e-05, \"mean_score_time\": 0.0112687349319458, \"std_score_time\": 0.00013712323880286207, \"param_kneighborsclassifier__n_neighbors\": 36, \"params\": {\"kneighborsclassifier__n_neighbors\": 36}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9166666666666666, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8195652173913043, \"std_test_score\": 0.06678962353707588, \"rank_test_score\": 34}, {\"mean_fit_time\": 0.010306572914123536, \"std_fit_time\": 0.00012179402333874086, \"mean_score_time\": 0.011338520050048827, \"std_score_time\": 0.0002217157882770461, \"param_kneighborsclassifier__n_neighbors\": 37, \"params\": {\"kneighborsclassifier__n_neighbors\": 37}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.875, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8278985507246377, \"std_test_score\": 0.07524988128549015, \"rank_test_score\": 31}, {\"mean_fit_time\": 0.010237026214599609, \"std_fit_time\": 3.8439966582532013e-05, \"mean_score_time\": 0.011275339126586913, \"std_score_time\": 0.00015106551119334477, \"param_kneighborsclassifier__n_neighbors\": 38, \"params\": {\"kneighborsclassifier__n_neighbors\": 38}, \"split0_test_score\": 0.75, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8237318840579709, \"std_test_score\": 0.0736633053574551, \"rank_test_score\": 33}, {\"mean_fit_time\": 0.01045222282409668, \"std_fit_time\": 0.00036055706466940455, \"mean_score_time\": 0.011552166938781739, \"std_score_time\": 0.0005769603709155503, \"param_kneighborsclassifier__n_neighbors\": 39, \"params\": {\"kneighborsclassifier__n_neighbors\": 39}, \"split0_test_score\": 0.7083333333333334, \"split1_test_score\": 0.9166666666666666, \"split2_test_score\": 0.7083333333333334, \"split3_test_score\": 0.7916666666666666, \"split4_test_score\": 0.9583333333333334, \"split5_test_score\": 0.8333333333333334, \"split6_test_score\": 0.8333333333333334, \"split7_test_score\": 0.75, \"split8_test_score\": 0.8260869565217391, \"split9_test_score\": 0.8695652173913043, \"mean_test_score\": 0.8195652173913043, \"std_test_score\": 0.07872080362480703, \"rank_test_score\": 34}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_versus_k_grid = (\n",
    "    alt.Chart(accuracies_grid)\n",
    "    .mark_line(point=True)\n",
    "    .properties(title='Figure 1: Mean Test Score against K (Number of Neighbors)')\n",
    "    .encode(\n",
    "        x = alt.X('param_kneighborsclassifier__n_neighbors', title='Number of Neighbors', scale=alt.Scale(zero=False)),\n",
    "        y = alt.Y('mean_test_score', title='Mean Test Score', scale=alt.Scale(zero=False))\n",
    "    )\n",
    ")\n",
    " \n",
    "accuracy_versus_k_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489e7a1-e0f2-447e-a016-dd2c6e86b136",
   "metadata": {},
   "source": [
    "#### Selecting $K$\n",
    "A `n_neighbours` of 19 with the highest accuracy was chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b76ded6e-2440-43d9-989a-46b9f605322c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_spec = KNeighborsClassifier(n_neighbors=19)\n",
    "cleveland_fit = make_pipeline(cleveland_preprocessor, knn_spec).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db061bda-58e3-419e-8313-ef6efb2fe773",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease_presence</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.213487</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>-0.949499</td>\n",
       "      <td>-0.824686</td>\n",
       "      <td>0.894102</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>0.980241</td>\n",
       "      <td>0.422524</td>\n",
       "      <td>-0.665062</td>\n",
       "      <td>0.631275</td>\n",
       "      <td>0.613559</td>\n",
       "      <td>-0.833663</td>\n",
       "      <td>-0.880854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-1.301117</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>-0.949499</td>\n",
       "      <td>-0.242829</td>\n",
       "      <td>-0.495805</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>0.980241</td>\n",
       "      <td>1.618346</td>\n",
       "      <td>-0.665062</td>\n",
       "      <td>-0.877081</td>\n",
       "      <td>-0.973232</td>\n",
       "      <td>-0.833663</td>\n",
       "      <td>-0.880854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.403533</td>\n",
       "      <td>-1.295597</td>\n",
       "      <td>-1.911828</td>\n",
       "      <td>0.339029</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>-1.033953</td>\n",
       "      <td>0.038152</td>\n",
       "      <td>-0.665062</td>\n",
       "      <td>0.631275</td>\n",
       "      <td>-0.973232</td>\n",
       "      <td>1.216328</td>\n",
       "      <td>-0.880854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.321673</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>-1.911828</td>\n",
       "      <td>-0.010086</td>\n",
       "      <td>-0.816553</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>-1.033953</td>\n",
       "      <td>0.507940</td>\n",
       "      <td>-0.665062</td>\n",
       "      <td>-0.206701</td>\n",
       "      <td>-0.973232</td>\n",
       "      <td>1.216328</td>\n",
       "      <td>-0.880854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.187161</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.975161</td>\n",
       "      <td>1.502745</td>\n",
       "      <td>0.936869</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>0.980241</td>\n",
       "      <td>-1.798289</td>\n",
       "      <td>1.503619</td>\n",
       "      <td>0.379882</td>\n",
       "      <td>0.613559</td>\n",
       "      <td>2.241324</td>\n",
       "      <td>-0.880854</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.213487</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.975161</td>\n",
       "      <td>0.688144</td>\n",
       "      <td>-0.517188</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>-1.033953</td>\n",
       "      <td>-1.926413</td>\n",
       "      <td>-0.665062</td>\n",
       "      <td>0.798870</td>\n",
       "      <td>0.613559</td>\n",
       "      <td>0.191333</td>\n",
       "      <td>1.183648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.219257</td>\n",
       "      <td>-1.295597</td>\n",
       "      <td>0.012831</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1.321766</td>\n",
       "      <td>1.920286</td>\n",
       "      <td>-1.033953</td>\n",
       "      <td>0.849603</td>\n",
       "      <td>-0.665062</td>\n",
       "      <td>-0.877081</td>\n",
       "      <td>-0.973232</td>\n",
       "      <td>-0.833663</td>\n",
       "      <td>-0.880854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.078975</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>-0.949499</td>\n",
       "      <td>1.502745</td>\n",
       "      <td>0.081541</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>-1.033953</td>\n",
       "      <td>-1.285794</td>\n",
       "      <td>1.503619</td>\n",
       "      <td>-0.877081</td>\n",
       "      <td>0.613559</td>\n",
       "      <td>2.241324</td>\n",
       "      <td>0.667522</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.105301</td>\n",
       "      <td>-1.295597</td>\n",
       "      <td>0.975161</td>\n",
       "      <td>-0.359200</td>\n",
       "      <td>1.300383</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>0.980241</td>\n",
       "      <td>0.379816</td>\n",
       "      <td>-0.665062</td>\n",
       "      <td>-0.877081</td>\n",
       "      <td>-0.973232</td>\n",
       "      <td>0.191333</td>\n",
       "      <td>-0.880854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.646231</td>\n",
       "      <td>-1.295597</td>\n",
       "      <td>0.975161</td>\n",
       "      <td>0.339029</td>\n",
       "      <td>0.551971</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>0.980241</td>\n",
       "      <td>0.422524</td>\n",
       "      <td>-0.665062</td>\n",
       "      <td>2.139631</td>\n",
       "      <td>2.200350</td>\n",
       "      <td>1.216328</td>\n",
       "      <td>-0.880854</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "22   0.213487  0.771845 -0.949499 -0.824686  0.894102 -0.520756  0.980241   \n",
       "53  -1.301117  0.771845 -0.949499 -0.242829 -0.495805 -0.520756  0.980241   \n",
       "30   1.403533 -1.295597 -1.911828  0.339029 -0.068141 -0.520756 -1.033953   \n",
       "274  0.321673  0.771845 -1.911828 -0.010086 -0.816553 -0.520756 -1.033953   \n",
       "1    1.187161  0.771845  0.975161  1.502745  0.936869 -0.520756  0.980241   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "251  0.213487  0.771845  0.975161  0.688144 -0.517188 -0.520756 -1.033953   \n",
       "63  -0.219257 -1.295597  0.012831  0.048100  1.321766  1.920286 -1.033953   \n",
       "187  1.078975  0.771845 -0.949499  1.502745  0.081541 -0.520756 -1.033953   \n",
       "102  0.105301 -1.295597  0.975161 -0.359200  1.300383 -0.520756  0.980241   \n",
       "6    0.646231 -1.295597  0.975161  0.339029  0.551971 -0.520756  0.980241   \n",
       "\n",
       "      thalach     exang   oldpeak     slope        ca      thal  \\\n",
       "22   0.422524 -0.665062  0.631275  0.613559 -0.833663 -0.880854   \n",
       "53   1.618346 -0.665062 -0.877081 -0.973232 -0.833663 -0.880854   \n",
       "30   0.038152 -0.665062  0.631275 -0.973232  1.216328 -0.880854   \n",
       "274  0.507940 -0.665062 -0.206701 -0.973232  1.216328 -0.880854   \n",
       "1   -1.798289  1.503619  0.379882  0.613559  2.241324 -0.880854   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "251 -1.926413 -0.665062  0.798870  0.613559  0.191333  1.183648   \n",
       "63   0.849603 -0.665062 -0.877081 -0.973232 -0.833663 -0.880854   \n",
       "187 -1.285794  1.503619 -0.877081  0.613559  2.241324  0.667522   \n",
       "102  0.379816 -0.665062 -0.877081 -0.973232  0.191333 -0.880854   \n",
       "6    0.422524 -0.665062  2.139631  2.200350  1.216328 -0.880854   \n",
       "\n",
       "     heart_disease_presence  predicted  \n",
       "22                        1          0  \n",
       "53                        0          0  \n",
       "30                        0          0  \n",
       "274                       1          0  \n",
       "1                         1          1  \n",
       "..                      ...        ...  \n",
       "251                       1          1  \n",
       "63                        0          0  \n",
       "187                       1          1  \n",
       "102                       0          0  \n",
       "6                         1          1  \n",
       "\n",
       "[75 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleveland_test_predictions = cleveland_test_scaled.assign(\n",
    "    predicted = cleveland_fit.predict(cleveland_test_scaled)\n",
    ")\n",
    "cleveland_test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c008e6b-6d1d-4be1-9b5a-4e6544af7124",
   "metadata": {},
   "source": [
    "### Determining Accuracy\n",
    "\n",
    "With the selected `n_neighbours`, we tested our model with the testing set (75 observations) by using the predict() method and calculated the model’s accuracy based on the number of correct predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80dbc3f5-b836-43cc-822f-d7222d75cf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = cleveland_test_scaled.drop(columns = {'heart_disease_presence'})\n",
    "y_test = cleveland_test_scaled['heart_disease_presence']\n",
    "\n",
    "cleveland_prediction_accuracy = cleveland_fit.score(X_test, y_test)\n",
    "cleveland_prediction_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4633f9-02fa-498a-a769-d5ca9c3fcec0",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "A confusion matrix (Figure 2) was generated to show four kinds of predictions generated with this model, as well as the precision and recall were calculated based on the prediction result from the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34ec046f-bf21-43de-8f22-450d74534cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Label')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay.from_estimator(cleveland_fit, X_test, y_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6)) \n",
    "disp.plot()\n",
    "plt.title('Figure 2: Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e89d379-4ee1-485b-810e-aa665b5ba25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = cleveland_test_predictions['heart_disease_presence']\n",
    "y_pred = cleveland_test_predictions['predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b293545-bcda-49f8-88b3-bf29759a4d5c",
   "metadata": {},
   "source": [
    "#### Precision and Recall\n",
    "\n",
    "Finally, we were able to determine the precision and recall of our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "757c58ad-6cd2-410b-ae7c-16b785abd161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c64df30-1db8-4058-934e-090904255557",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_true, y_pred)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963713c-11a2-4290-ae10-a6e54c060d78",
   "metadata": {},
   "source": [
    "## Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a45ce-6e5d-4a7d-bd10-1895009dc5a2",
   "metadata": {},
   "source": [
    "The goal of our project was to build an accurate classification model to predict the presence of heart disease or not based on available predictor variables. \n",
    "We first decided to convert the response variable heart disease presence level 1-4 to 1 meaning presence, and level 0 remains as no presence of heart disease. Since our classifier is only detecting the presence of heart disease and not the stage of heart disease, changing all the positive values to 1 and keeping all zeros as 0 was effective enough to the purpose of this classifier. \n",
    "Using the selected 4 predictor variables (`trestbps`, `chol`, `thalach`, `oldpeak`) from the proposal after changing the levels 1-4 to 1 in the heart disease presence variable, we obtained a high false negative value, a recall of 50.0% and a precision of 85.7%. To decrease the false negative value for clinical purposes, we balanced the samples from level 0 with 124 data counts and level 1 with 103 data counts to both levels having 124 data counts. Through balancing the data, we increased the recall to 55.6%; however, precision was lowered to 69.0%. \n",
    "We then realized the difficulties in obtaining an ideal recall and lowering false positive cases may be due to the loss of information from dropping the categorical columns. The wrong assumption of the classification model should be trained mainly on quantitative data resulting in an inaccurate clinical model. By restoring all categorical columns (specified in the methods) and training the model on the balanced heart disease presence dataset, we obtained the final model with 84% accuracy, 86.7% precision and 76.5% recall, which outcompeted the models trained with only 4 predictor variables. As such, we were able to build a highly accurate classifier. The 2x2 confusion matrix provides a clear representation of four kinds of prediction that this classifier can make and as a disease classifier, a low false nagative errror rate, as indicated by the lower left box in the confusion matrix (Figure 2), is also an indicator of a well-established model.   \n",
    "\n",
    "As mentioned previously, our goal is to have a classifier that can accurately predict whether or not a patient has heart disease. The current model is 84% accurate in predicting a randomly drewed testing set using K-nearest neighbours classifier with number of neighbours equals to 3 (n = 3). The 84% prediction accuracy was obtained from a 10 fold cross-validation and n = 3 was determined by plotting the accuracies versus number of K-neighbours and obtaining the number of K that returned the highest prediction accuracy. This is an ideal accuracy that we are expected to find with current ability. Also, a current recall of 76.5% is higher than previous models trained with 4 predictor variables which indicates an increase in ratio between the number of correct positive predictions and total number of positive test set observations. Therefore, an increase in recall represents a decrease in false negatives, which benefits this model’s clinical utility.\n",
    "\t\n",
    "The development of an accurate classification model for predicting the presence of heart disease based on various predictor variables could have impacts on clinical diagnosis improvement, early intervention and variables selection. The classifier with an 84% accuracy can potentially assist healthcare professionals in diagnosing the presence of heart disease more effectively. The model’s ability to balance precision (86.7%) and recall (76.5%) is crucial in a clinical setting. High precision ensures that positive predictions are reliable, while a high recall can indicate proportion of actual positive cases, reducing the chances of false negatives. A reliable heart disease prediction model can contribute to early intervention with early diagnosis. This could lead to a reduction in the severity of heart-related diseases. The 13 predictor variables used in this model are selected to show a relationship with heart disease identification, so they are a guide to doctors when diagnosing a patient with heart disease.\n",
    "\n",
    "Other impacts that our findings have on building clinical classifiers are consideration of categorial variables and trade-offs in precision and recall. The realization that including categorical variables in the model can improve its performance highlights the significance of considering various types of data in healthcare analytics. This insight could influence the design of future classification models for medical diagnoses. Two abandoned models demonstrate the trade-offs between precision and recall and how balancing the dataset can impact model performance. By balancing the dataset, the precision dropped from 85% to 69% while recall increased from 50% to 55%. It is important for healthcare analyticians to decide whether it’s more important to minimize false positives or false negatives based on the context of the medical application.\n",
    "Since this classifier is 81% accurate, there is a great space for improvement, which could lead to further research, such as exploring additional predictor variables, investigating the generalizability of the model to different patient populations, and comparing with other existing classifiers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618f6cd-13e3-41a1-9b33-af6da9164f65",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J.-J., Sandhu, S., Guppy, K. H., Lee, S., & Froelicher, V. (1989). International application of a new probability algorithm for the diagnosis of coronary artery disease. The American Journal of Cardiology, 64(5), 304–310. https://doi.org/10.1016/0002-9149(89)90524-9\n",
    "2. Canada, Public Health Agency of. “Government of Canada.” Canada.Ca, / Gouvernement du Canada, 28 July 2022, www.canada.ca/en/public-health/services/publications/diseases-conditions/heart-disease-canada.html.   \n",
    "3. “Heart Disease.” UCI Machine Learning Repository, 1988, archive.ics.uci.edu/dataset/45/heart+disease.  \n",
    "4. Parry, R M, et al. “K-nearest neighbor models for microarray gene expression analysis and clinical outcome prediction.” The Pharmacogenomics Journal, vol. 10, no. 4, 2010, pp. 292–309, https://doi.org/10.1038/tpj.2010.56. \n",
    "5. Tayeb, Shahab, et al. “Toward predicting medical conditions using K-nearest neighbors.” 2017 IEEE International Conference on Big Data (Big Data), 2017, https://doi.org/10.1109/bigdata.2017.8258395. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
